---
title: "TDA Difficulty"
date: "Last updated `r Sys.Date()`"
output: 
  html_document:
    toc: TRUE
    code_folding: hide
---

To cite these data:
[add data paper reference here]

The goal of this project was to identify the *average* "difficulty"" of 2,818 trait descriptive adjectives (TDAs) in American English. Difficulty, in this usage, denotes the extent to which people in our sample correctly matched the personality-relevant definition for each adjective to the adjective itself when presented as one of six options. The other five options presented as choices were randomly sampled from the remaining 2,817 adjectives in the set. To control for inevitable error resulting from similarity between distractor choices and the matching definition-adjective pair, each TDA was administered twice, with two different sets of distractor sets. On this page, we report the total number of responses and the average proportion correct across both forms.

In our view, the total proportion correct reflects *both* familiarity of the adjective and consensus among raters about its meaning, especially as a descriptor of personality. For example, most of the terms with a low proportion of correct responses are unfamiliar to many individuals (i.e., rarely encountered in everyday language) -- "goatish" (.07), "pithy" (.10), "splenetic" (.10). Other terms -- "dizzying" (.04), "smooth" (.09) -- are familiar but ambiguous in meaning relative to personality. By contrast, terms with the highest proportion of correct responses are familiar *and* unambiguous -- "jolly" (1.00), "thankful" (1.00), "unreliable" (.99). When using ratings of terms such as these to evaluate the structure of personality, it's important to consider the extent to which each term is known to raters and consistently interpreted.

Statistics from the individual administrations of each term (i.e., each version or "form"") can be found [here](https://pie-lab.github.io/tda/item-difficulty.html).

The data can be downloaded [here](https://doi.org/10.7910/DVN/5T80PF).

Please consult the reference listed above for more information about this project.

```{r, include = F}
knitr::opts_chunk$set(echo = T, message = F, warning = F)
```

```{r}
library(here) # for engaging with working environment
library(tidyverse) # for data cleaning and manipulation
library(Hmisc) # for weighted means
library(DT) # for viewing data tables

data = read_csv(here("data/TDA_data_scored.csv"))
masterKey = read_csv(here("data/masterkey.csv"))

data = data %>%
  filter(included == "Yes") %>% # remove participants screend out for demographic and quality reasons
  select(starts_with("q_")) # select only TDA items

data_means = colMeans(data, na.rm = T) #calculate column means

all_item_means = data.frame( # create data frame with...
  item = names(data_means), # ...variable name and...
  prop_correct = data_means #... proportion correct
)

item_prop = masterKey %>% # join the masterKey (item name, correct adjective, and form)
  full_join(all_item_means) %>% # with proportion correct
  mutate(prop_correct = round(prop_correct, 2)) # round to 2 decimal places

# next we count the number of administrations of each item
item_prop$N = colSums(!is.na(data)) # count non-missing

```

```{r}
# create table 
item_prop = item_prop %>%
  group_by(adjective) %>% # for each unique adjective
  mutate(weight = N/sum(N)) %>% # create a new variable that is the number of responses (per item) divided by the total number of responses (across both items)
  summarise(
    N = sum(N), # how many total responses 
    prop = wtd.mean(prop_correct, weights = weight, na.rm=T) # average proportion, weighted by sample size
  ) %>%
  mutate(prop = round(prop, 2)) # round to 2

item_prop %>%
  DT::datatable( # put into interactive HTML table
    colnames = c("Adjective", "N (total)", "Proportion Correct"), #colnames
    filter = "top", # can filter
    rownames = F # don't need rownames
  )
```

```{r}
write_csv(item_prop, file = here("data/tda_difficulty.csv"))
```



